---
title: "StarWars_aNewHope"
output: html_document
date: "2023-02-17"
---

This little pet project is a study in hope and character journeys. Star Wars, a story that really concerns itself with our powers and how to use them - personally, interpersonally, intergalactically. The Force, the universal current running through all things, has poles to it, and we see the worlds and characters standing on precipice of light and darkness through the experiences and ideas that shape them and the choices they make. It's a vote to fight the good fight. Use the force for what is good; be wise to the abyss. Feed the impulses in you that are like the jedi, that represent good things like courage, love, compassion, wisdom, hope 

Besides the survival instinct built into hope, and my forever deep love of Star Wars, the relinquishing of deliberate cognitive directedness in using something like The Force as a guide is also hitting different right now for me. The trusting of neural network activity below the level of executive consciousness that allows for creative work, including work toward authenticity, that surfaces emotional knowledge more complete than either concept or feeling, is another nod toward Star Wars and sentiment analysis for me now, because this pet project was calling out to me like a hologram message "you're my only hope"

And here we are, let's listen and look in: 

#Explore
```{r setup, include=FALSE}
getwd()
knitr::opts_chunk$set(echo = TRUE)
```

#
```{r libraries}
library(Rcpp)
library(dplyr)
library(ggplot2)
library(tm)
library(wordcloud)
library(tidytext)
library(stringr)
library(ggthemes)
library(skimr)
library(DataExplorer)
```

#Data

```{r}
setwd("/Users/claudiaroman/Data")
eps4 <- read.table("SW_EpisodeIV.txt")
eps5 <- read.table("SW_EpisodeV.txt")
eps6 <-  read.table("SW_EpisodeVI.txt") 
str(eps4) 
str(eps5)
str(eps6)
```

#Explore

```{r}
eps4$eps = 4
eps5$eps = 5
eps6$eps = 6
starwars <- rbind(eps4, eps5, eps6)
str(starwars)
skim(starwars)
DataExplorer::create_report(starwars)
```

```{r}
#changing dialogue data type to character 
starwars$dialogue <- as.character(starwars$dialogue)
eps4$dialogue <- as.character(eps4$dialogue)
eps5$dialogue <- as.character(eps5$dialogue)
eps6$dialogue <- as.character(eps6$dialogue)
```


```{r}
#The top ten character with highest count of scenes in all episodes 
top10 <- starwars %>%
group_by(character) %>%
  summarise(freq = n()) %>% 
  arrange(desc(freq)) %>% 
  slice(1:10)  #order the first 10 in descinding order 
  ggplot(top10, aes(reorder(character, +freq), y = freq)) +
  geom_col(fill = "goldenrod2" , col = "grey20") +
    coord_flip() +
    labs(x = "", y = "Frequency", title = "Top 10 characters") 
    
```

```{r}
#The top ten character in episode 4
top4 <- eps4 %>%
group_by(character) %>%
  summarise(freq = n()) %>% 
  arrange(desc(freq)) %>% 
  slice(1:10)  #order the first 10 in descinding order 
  ggplot(top4, aes(reorder(character, +freq), y = freq)) +
  geom_col(fill = "goldenrod2" , col = "grey20") +
    coord_flip() +
    labs(x = "", y = "Frequency", title = "A new hope top 10 characters")
```

```{r}
#The top ten character in episode 5
top5 <- eps5 %>%
group_by(character) %>%
  summarise(freq = n()) %>% 
  arrange(desc(freq)) %>% 
  slice(1:10)  #order the first 10 in descinding order 
  ggplot(top5, aes(reorder(character, +freq), y = freq)) +
  geom_col(fill = "goldenrod2" , col = "grey20") +
    coord_flip() +
    labs(x = "", y = "Frequency", title = "The Empire Strikes Back top 10 characters")
```

```{r}
#The top ten character in episode 6
top6 <- eps6 %>%
group_by(character) %>%
  summarise(freq = n()) %>% 
  arrange(desc(freq)) %>% 
  slice(1:10)  #order the first 10 in descinding order 
  ggplot(top6, aes(reorder(character, +freq), y = freq)) +
  geom_col(fill = "goldenrod2" , col = "grey20") +
    coord_flip() +
    labs(x = "", y = "Frequency", title = "Return of the Jedi top 10 characters ")
```

```{r}
#Extracting the dialogue attribute 
dialogue <- starwars$dialogue
head(dialogue)
#changing it to corpus for easier text analysis 
dia.cor <- VCorpus(VectorSource(dialogue))
dia.cor <- tm_map(dia.cor, content_transformer(tolower))
dia.cor <- tm_map(dia.cor, removeWords, stopwords("english"))
dia.cor <- tm_map(dia.cor, removeWords, c("sir", "master", "force"))
dia.cor <- tm_map(dia.cor, removePunctuation) #remove the punctuations
dia.cor <- tm_map(dia.cor, stemDocument) #Stem words in a text document 
dia.cor <- tm_map(dia.cor, removeNumbers)
dia.cor <- tm_map(dia.cor, stripWhitespace)#remove white spaces at the beginning and end not spaces between words
#removing the stopwords
head(dia.cor)
```

```{r}
#putting all our data in a matrix  
#and count how many times the word occure in each document 
td.mat <- TermDocumentMatrix(dia.cor)
#converting from term document matrix to matrix 
td.mat <- as.matrix(td.mat)
```

```{r}
#finding the total frequency of a word
wordcount <- rowSums(td.mat)
wordcount <- sort(wordcount, decreasing = T) #The highest word frequency 
#top 50 wordcounts 
wc <- wordcount[1:50]
#converting it to dataframe because wordcloud2 only deals with dataframes 
wc <- as.data.frame(wc)
wc$count <- wc$wc
wc$word <- names(wordcount[1:50])
wc.df <- subset(wc, select = c(word, count))
str(wc.df)
wc.df$word <- as.factor(wc.df$word)
#wordcloud visualization 
wordcloud(wc.df$word, wc.df$count, max.words=100, random.order=FALSE, rot.per=0.25, 
          colors=brewer.pal(8, "Dark2"))
```


```{r}
#converting to data frame word count 
wordcount.df <- as.data.frame(wordcount)
```

```{r}
#saving star wars file 
file <- write.table(starwars, file = "starwars.txt")
```

```{r}
#unnest_tokens Split a column into tokens using the tokenizers package, splitting the table into one-token-per-row.
tidy.starwars <- starwars %>%
  unnest_tokens(word, dialogue) %>% #Break the dialogue into individual word 
  filter(nchar(word) > 2, word != "lord", word != "sir", word !=  "master", word != "force") %>% #words that are less than 3 letterse like in, on.. and some other words I don't want to include in my analysis 
  anti_join(stop_words)
```

```{r}
#after tokenizing it's time to count the words in the dialogue and get the sentiments of the words either they are negative or positive words (using bing)
bing.count <- tidy.starwars %>%
  inner_join(get_sentiments("bing")) %>%
  count( word, sentiment, sort = T) 
```
```{r}
#Top 10 positive vs negative words in the dialogue 
bing.count %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Top 10 positive vs negative words in the dialogue ",
       x = "") +
  coord_flip() +
   theme_economist()
```

```{r}
#after tokenizing it's time to count the words in the dialogue and get the sentiments of the words either they are negative or positive  or other feelings (using nrc)
nrc.count <- tidy.starwars %>%
  inner_join(get_sentiments("nrc")) %>%
  count( word, sentiment, sort = T) %>%
  ungroup()
```

```{r}
#Top 10 used words based on the feeling  
nrc.count %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "", y = "Top 10 positive vs negative words in the dialogue ") +
  coord_flip() +
  theme_economist()
```

```{r}
tidy.starwars %>%
  inner_join(get_sentiments("nrc")) %>%
   count(word, sentiment, sort = T, character) %>%
  mutate(word = reorder(word, n)) %>%
  filter(character %in% c("LUKE","HAN","THREEPIO", "LEIA", "VADER")) %>%
  ggplot(aes(sentiment, n, fill = character))+
  geom_col(show.legend = FALSE) +
  facet_wrap(~character, scales = "free_y") +
  labs(x = "", y = "Top 10 positive vs negative words in the dialogue ") +
  coord_flip() +
  theme_economist()
```


```{r}
#looks like c3-po is the most trusting and positive character 
tidy.starwars %>%
  inner_join(get_sentiments("nrc")) %>%
   count(word, sentiment, sort = T, character) %>%
  mutate(word = reorder(word, n)) %>%
  filter(character %in% c("LUKE","HAN","THREEPIO", "LEIA", "VADER")) %>%
  ggplot(aes(character, n, fill = sentiment)) +
  geom_col(show.legend = T, position = "dodge") +
  labs(x = "", y = "") +
  coord_flip() +
  theme_economist()
tidy.starwars %>%
  inner_join(get_sentiments("bing")) %>%
   count(word, sentiment, sort = T, character) %>%
  mutate(word = reorder(word, n)) %>%
  filter(character %in% c("LUKE","HAN","THREEPIO", "LEIA", "VADER", "BEN", "LANDO", "YODA", "EMPEROR", "RED LEADER")) %>%
  ggplot(aes(character, n, fill = sentiment)) +
  geom_col(show.legend = T) +
  labs(x = "", y = "") +
  coord_flip() +
  theme_economist()
#lexicon assigns words with a score that runs between -5 and 5, with negative scores indicating negative sentiment and positive scores indicating positive sentiment
tidy.starwars %>%
  inner_join(get_sentiments("afinn")) %>%
   count(word, value, sort = T, character) %>%
  mutate(n = reorder(value, n)) %>%
  filter(character %in% c("LUKE","HAN","THREEPIO", "LEIA", "VADER")) %>%
  ggplot(aes(character, n, fill = value)) +
  geom_col(show.legend = T, position = "dodge") +
  labs(x = "", y = "") +
  coord_flip() +
  scale_fill_manual(values = c("red", "grey", "seagreen3", "cyan3", "yellow", "purple"))
```
